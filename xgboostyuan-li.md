首先说下决策树

决策树是啥？

举个例子，有一堆人，我让你分出男女，你依靠头发长短将人群分为两拨，长发的为“女”，短发为“男”，你是不是依靠一个指标“头发长短”将人群进行了划分，你就形成了一个简单的决策树，官方细节版本自行baidu或google

划分的依据是啥？

这个时候，你肯定问，为什么用“头发长短”划分啊，我可不可以用“穿的鞋子是否是高跟鞋”，“有没有喉结”等等这些来划分啊，Of course！那么肯定就需要判断了，那就是哪一种分类效果好，我就选哪一种啊。

分类效果如何评价量化呢？

怎么判断“头发长短”或者“是否有喉结”…是最好的划分方式，效果怎么量化。直观来说，如果根据某个标准分裂人群后，纯度越高效果越好，比如说你分为两群，“女”那一群都是女的，“男”那一群全是男的，这个效果是最好的，但事实不可能那么巧合，所以越接近这种情况，我们认为效果越好。于是量化的方式有很多，信息增益（ID3）、信息增益率（C4.5）、基尼系数（CART）等等，来用来量化纯度

其他细节如剪枝、过拟合、优缺点、并行情况等自己去查吧。决策树的灵魂就已经有了，依靠某种指标进行树的分裂达到分类/回归的目的（上面的例子是分类），总是希望纯度越高越好。

说下Xgboost的建树过程

Xgboost是很多CART回归树集成

概念1：回归树与决策树

事实上，分类与回归是一个型号的东西，只不过分类的结果是离散值，回归是连续的，本质是一样的，都是特征（feature）到结果/标签（label）之间的映射。说说决策树和回归树，在上面决策树的讲解中相信决策树分类已经很好理解了。

回归树是个啥呢？

直接摘抄人家的一句话，分类树的样本输出（即响应值）是类的形式，如判断蘑菇是有毒还是无毒，周末去看电影还是不去。而回归树的样本输出是数值的形式，比如给某人发放房屋贷款的数额就是具体的数值，可以是0到120万元之间的任意值。

那么，这时候你就没法用上述的信息增益、信息增益率、基尼系数来判定树的节点分裂了，你就会采用新的方式，预测误差，常用的有均方误差、对数误差等。而且节点不再是类别，是数值（预测值），那么怎么确定呢，有的是节点内样本均值，有的是最优化算出来的比如Xgboost。

概念2：boosting集成学习，由多个相关联的决策树联合决策，什么叫相关联，举个例子，有一个样本\[数据-&gt;标签\]是\[\(2，4，5\)-&gt; 4\]，第一棵决策树用这个样本训练得预测为3.3，那么第二棵决策树训练时的输入，这个样本就变成了\[\(2，4，5\)-&gt; 0.7\]，也就是说，下一棵决策树输入样本会与前面决策树的训练和预测相关。



与之对比的是random foreast（随机森林）算法，各个决策树是独立的、每个决策树在样本堆里随机选一批样本，随机选一批特征进行独立训练，各个决策树之间没有啥毛线关系。



所以首先Xgboost首先是一个boosting的集成学习，这样应该很通俗了



这个时候大家就能感觉到一个回归树形成的关键点：（1）分裂点依据什么来划分（如前面说的均方误差最小，loss）；（2）分类后的节点预测值是多少（如前面说，有一种是将叶子节点下各样本实际值得均值作为叶子节点预测误差，或者计算所得）



是时候看看Xgboost了



首先明确下我们的目标，希望建立K个回归树，使得树群的预测值尽量接近真实值（准确率）而且有尽量大的泛化能力（更为本质的东西），从数学角度看这是一个泛函最优化，多目标，看下目标函数： 

L\(ϕ\)=∑il\(ŷ i−yi\)+∑kΩ\(fk\)

L\(ϕ\)=∑il\(y^i−yi\)+∑kΩ\(fk\)



其中ii表示第i个样本，l\(\(ŷ i−yi\)l\(\(y^i−yi\)表示第ii个样本的预测误差，误差越小越好，不然你算得上预测么？后面∑kΩ\(fk\)∑kΩ\(fk\)表示树的复杂度的函数，越小复杂度越低，泛化能力越强，这意味着啥不用我多说。表达式为 

Ω\(f\)=γT+12λ\|\|w\|\|2

Ω\(f\)=γT+12λ\|\|w\|\|2



TT表示叶子节点的个数，ww表示节点的数值（这是回归树的东西，分类树对应的是类别）

直观上看，目标要求预测误差尽量小，叶子节点尽量少，节点数值尽量不极端（这个怎么看，如果某个样本label数值为4，那么第一个回归树预测3，第二个预测为1；另外一组回归树，一个预测2，一个预测2，那么倾向后一种，为什么呢？前一种情况，第一棵树学的太多，太接近4，也就意味着有较大的过拟合的风险）



ok，听起来很美好，可是怎么实现呢，上面这个目标函数跟实际的参数怎么联系起来，记得我们说过，回归树的参数:（1）选取哪个feature分裂节点呢；（2）节点的预测值（总不能靠取平均值这么粗暴不讲道理的方式吧，好歹高级一点）。上述形而上的公式并没有“直接”解决这两个，那么是如何间接解决的呢？



先说答案：贪心策略+最优化（二次最优化，恩你没看错）



